{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import cognitive_GLVQ as cglvq\n",
    "import GLVQ as glvq\n",
    "import optimizer as opt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {\n",
    "    0: \"Not sick\",\n",
    "    1: \"A kappa\",\n",
    "    2: \"A lambda\",\n",
    "    3: \"M kappa\",\n",
    "    4: \"M lambda\",\n",
    "    5: \"G kappa\",\n",
    "    6: \"G lambda\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prototypes = 2\n",
    "colors = [\"#5171fF\", \"#fF7151\", \"#519951\"]\n",
    "img_folder = \"images/figs/\"\n",
    "data_name = \"nsp_f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_figs(model, experiment, model_name, lr):\n",
    "    fig1 = model.lr_graph(f\"{model_name} Learning Rate\")\n",
    "    fig2 = model.acc_graph(f\"{model_name} Accuracy\")\n",
    "    fig3 = model.f1_graph(f\"{model_name} F1 Score\")\n",
    "    figs = [fig1, fig2, fig3]\n",
    "    fig_type = [\"lr\", \"acc\", \"f1\"]\n",
    "    for i, fig in enumerate(figs):\n",
    "        fig.savefig(f\"{img_folder}/{experiment}/{data_name}/{model_name}_{lr}_{fig_type[i]}.png\", dpi = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir = \"dataset/feature/inputs_wo_ud_wo_sp_f.npy\"\n",
    "label_dir = \"dataset/label/labels_wo_ud.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.load(feature_dir)\n",
    "label = np.load(label_dir)\n",
    "label = label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, count = np.unique(label, return_counts=True)\n",
    "sample_number = dict(zip(unique, count))\n",
    "sample_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(sample_number.items()):\n",
    "    if i == 0:\n",
    "        color = colors[i]\n",
    "    else:\n",
    "        color = colors[1]\n",
    "    ax.bar(label_names[k], v, width=0.5, color=color)\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()\n",
    "fig.savefig(\"images/figs/NSP_f/group_sample.png\", dpi = 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype selection\n",
    "prototype_index = []\n",
    "\n",
    "index_normal = np.where(label == 0)\n",
    "index_normal = list(index_normal[0])\n",
    "prototype_normal_index = random.sample(index_normal, num_prototypes*6)\n",
    "prototype_index += prototype_normal_index\n",
    "for class_name in sample_number:\n",
    "    if class_name != 0:\n",
    "        index_abnormal = np.where(label == class_name)\n",
    "        index_abnormal = list(index_abnormal[0])\n",
    "        prototype_abnormal_index = random.sample(index_abnormal, num_prototypes)\n",
    "        prototype_index += prototype_abnormal_index\n",
    "# Change labels to binary classes\n",
    "label = np.where(label == 0, label, 1)\n",
    "# Add prototypes to dataset\n",
    "prototype_index.sort(reverse=True)\n",
    "prototypes = [(feature[i],label[i]) for i in prototype_index]\n",
    "## Remove prototypes from dataset\n",
    "feature = np.delete(feature, prototype_index, axis=0)\n",
    "label = np.delete(label, prototype_index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, count = np.unique(label, return_counts=True)\n",
    "sample_number = dict(zip(unique, count))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(sample_number.items()):\n",
    "    if k == 0:\n",
    "        label_name = \"Normal\"\n",
    "    else:\n",
    "        label_name = \"Abnormal\"\n",
    "    ax.bar(label_name, v, width=0.5, color=colors[i])\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()\n",
    "fig.savefig(\"images/figs/NSP_f/number_of_samples.png\", dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"experiment_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select equal amount of normal and abnormal data\n",
    "data_per_class = min(count) - num_prototypes\n",
    "test_percentage = 0.15\n",
    "test_size = int(test_percentage * data_per_class)\n",
    "train_size = data_per_class - test_size\n",
    "feature_acc = copy.deepcopy(feature)\n",
    "label_acc = copy.deepcopy(label)\n",
    "\n",
    "## Select test set\n",
    "test_index = []\n",
    "for class_name in sample_number:\n",
    "    index_i = np.where(label_acc == class_name)\n",
    "    index_i = list(index_i[0])\n",
    "    index_i_sample = random.sample(index_i, test_size)\n",
    "    test_index += index_i_sample\n",
    "test_index.sort(reverse=True)\n",
    "test_set_acc = [(feature_acc[i],label_acc[i]) for i in test_index]\n",
    "random.shuffle(test_set_acc)\n",
    "unique, counts = np.unique(label_acc[test_index], return_counts=True)\n",
    "test_dist = dict(zip(unique, counts))\n",
    "feature_acc = np.delete(feature_acc, test_index, axis=0)\n",
    "label_acc = np.delete(label_acc, test_index, axis=0)\n",
    "\n",
    "## Select train set\n",
    "train_index = []\n",
    "for class_name in sample_number:\n",
    "    index_i = np.where(label_acc == class_name)\n",
    "    index_i = list(index_i[0])\n",
    "    index_i_sample = random.sample(index_i, train_size)\n",
    "    train_index += index_i_sample\n",
    "train_index.sort(reverse=True)\n",
    "unique, counts = np.unique(label_acc[train_index], return_counts=True)\n",
    "train_dist = dict(zip(unique, counts))\n",
    "train_set_acc = [(feature_acc[i],label_acc[i]) for i in train_index]\n",
    "random.shuffle(train_set_acc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(train_dist.items()):\n",
    "    if k == 0:\n",
    "        label_name = \"Normal\"\n",
    "    else:\n",
    "        label_name = \"Abnormal\"\n",
    "    ax.bar(label_name, v, width=0.5, color=colors[i])\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of training samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()\n",
    "fig.savefig(img_folder + experiment + \"/\" + data_name + \"/train_dist.png\", dpi=300)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(test_dist.items()):\n",
    "    if k == 0:\n",
    "        label_name = \"Normal\"\n",
    "    else:\n",
    "        label_name = \"Abnormal\"\n",
    "    ax.bar(label_name, v, width=0.5, color=colors[i])\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of testing samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()\n",
    "fig.savefig(img_folder + experiment + \"/\" + data_name + \"/test_dist.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GLVQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "glvq_acc = glvq.GLVQ(prototypes,learning_rate)\n",
    "hist = glvq_acc.train(num_epochs,train_set_acc,test_set_acc, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_acc, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "glvq_acc = glvq.GLVQ(prototypes,learning_rate,)\n",
    "hist = glvq_acc.train(num_epochs,train_set_acc,test_set_acc,sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_acc, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "glvq_acc = glvq.GLVQ(prototypes,learning_rate)\n",
    "hist = glvq_acc.train(num_epochs,train_set_acc,test_set_acc, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_acc, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "cp_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_acc, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "cp_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_acc, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "cp_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_acc, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "dfh_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.dual_factor_heuristic, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_acc, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "dfh_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.dual_factor_heuristic, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_acc, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "dfh_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.dual_factor_heuristic, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_acc, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "ms_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_acc, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "ms_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_acc, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "ms_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_acc, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "ls_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_acc, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "ls_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_acc, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "ls_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry,sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_acc, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "lsr_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry_rarity, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_acc, experiment, \"LSR\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "lsr_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry_rarity,sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_acc, experiment, \"LSR\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "lsr_glvq_acc = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_acc.train(num_epochs,train_set_acc, test_set_acc, opt.loose_symmetry_rarity, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_acc, experiment, \"LSR\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"experiment_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 20% of #sample-1 as #sample-2\n",
    "max_data = max(count) - num_prototypes\n",
    "data_per_class = [max_data, int(max_data/5)]\n",
    "test_percentage = 0.15\n",
    "test_size = list(map(lambda data: int(data * test_percentage), data_per_class)) \n",
    "train_size = [data - test for data, test in zip(data_per_class, test_size)]\n",
    "feature_f1 = copy.deepcopy(feature)\n",
    "label_f1 = copy.deepcopy(label)\n",
    "\n",
    "## Select test set\n",
    "test_index = []\n",
    "for j, class_name in enumerate(sample_number):\n",
    "    index_i = np.where(label_f1 == class_name)\n",
    "    index_i = list(index_i[0])\n",
    "    index_i_sample = random.sample(index_i, test_size[j])\n",
    "    test_index += index_i_sample\n",
    "test_index.sort(reverse=True)\n",
    "test_set_fscore = [(feature_f1[i],label_f1[i]) for i in test_index]\n",
    "random.shuffle(test_set_fscore)\n",
    "unique, counts = np.unique(label_f1[test_index], return_counts=True)\n",
    "test_dist = dict(zip(unique, counts))\n",
    "feature_f1 = np.delete(feature_f1, test_index, axis=0)\n",
    "label_f1 = np.delete(label_f1, test_index, axis=0)\n",
    "\n",
    "## Select train set\n",
    "train_index = []\n",
    "for j, class_name in enumerate(sample_number):\n",
    "    index_i = np.where(label_f1 == class_name)\n",
    "    index_i = list(index_i[0])\n",
    "    index_i_sample = random.sample(index_i, train_size[j])\n",
    "    train_index += index_i_sample\n",
    "train_index.sort(reverse=True)\n",
    "train_set_fscore = [(feature_f1[i],label_f1[i]) for i in train_index]\n",
    "random.shuffle(train_set_fscore)\n",
    "unique, counts = np.unique(label_f1[train_index], return_counts=True)\n",
    "train_dist = dict(zip(unique, counts))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(train_dist.items()):\n",
    "    if k == 0:\n",
    "        label_name = \"Normal\"\n",
    "    else:\n",
    "        label_name = \"Abnormal\"\n",
    "    ax.bar(label_name, v, width=0.5, color=colors[i])\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of training samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "for i, (k, v) in enumerate(test_dist.items()):\n",
    "    if k == 0:\n",
    "        label_name = \"Normal\"\n",
    "    else:\n",
    "        label_name = \"Abnormal\"\n",
    "    ax.bar(label_name, v, width=0.5, color=colors[i])\n",
    "    plt.text(k, v+0.1, str(v), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Number of testing samples in each class', fontsize=16)\n",
    "plt.xlabel('Class', fontsize=14)\n",
    "plt.ylabel('Number of samples', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GLVQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "glvq_fscore = glvq.GLVQ(prototypes,learning_rate)\n",
    "hist = glvq_fscore.train(num_epochs,train_set_fscore,test_set_fscore, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_fscore, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "glvq_fscore = glvq.GLVQ(prototypes,learning_rate,)\n",
    "hist = glvq_fscore.train(num_epochs,train_set_fscore,test_set_fscore,sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_fscore, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "glvq_fscore = glvq.GLVQ(prototypes,learning_rate)\n",
    "hist = glvq_fscore.train(num_epochs,train_set_fscore,test_set_fscore, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(glvq_fscore, experiment, \"OGLVQ\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "cp_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_fscore, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "cp_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_fscore, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "cp_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = cp_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.conditional_probability, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(cp_glvq_fscore, experiment, \"CP\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "dfh_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.dual_factor_heuristic, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_fscore, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "dfh_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.dual_factor_heuristic, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_fscore, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "dfh_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = dfh_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.dual_factor_heuristic, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(dfh_glvq_fscore, experiment, \"DFH\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "ms_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_fscore, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "ms_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_fscore, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "ms_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ms_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.middle_symmetry, sample_number=train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ms_glvq_fscore, experiment, \"MS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "ls_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_fscore, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "ls_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry, sample_number= train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_fscore, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "ls_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = ls_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry,sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(ls_glvq_fscore, experiment, \"LS\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-step lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "lsr_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry_rarity, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_fscore, experiment, \"LSR\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-step lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.03\n",
    "lsr_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry_rarity,sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_fscore, experiment, \"LSR\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-step lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "lsr_glvq_fscore = cglvq.CGLVQ(prototypes,learning_rate)\n",
    "hist = lsr_glvq_fscore.train(num_epochs,train_set_fscore, test_set_fscore, opt.loose_symmetry_rarity, sample_number = train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs(lsr_glvq_fscore, experiment, \"LSR\", learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
